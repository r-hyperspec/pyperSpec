{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#python-package-pyperspec","title":"Python Package pyperspec","text":"<p>This is a Python package designed to simplify the analysis and manipulation of hyperspectral datasets. The package provides an object-oriented approach providing a user-friendly interface that feels familiar to Python users, i.e. close to libraries such as <code>numpy</code>, <code>pandas</code>, and <code>scikit-learn</code>.</p> <p>This is heavily inspired by R package hyperSpec and part of <code>r-hyperspec</code>. The goal is to make the work with hyperspectral data sets, (i.e. spatially or time-resolved spectra, or spectra with any other kind of information associated with each of the spectra) more comfortable. The spectra can be data obtained during  XRF, UV/VIS,  Fluorescence, AES, NIR, IR,  Raman,  NMR,  MS, etc. spectroscopy measurements.</p> <p>NOTE: The main focus is not on algroithms since there are already many other good packages implementing algorithms, e.g.  numpy, scipy, pybaselines, and more can be found in FOSS For Spectroscopy list.</p> <p>Rather, it provides convinient interface for those algorithms and other routine tasks.</p> <p>For detailed information and documentation, please visit PyPerSpec Documentation.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>Please, check here</p>"},{"location":"#installation","title":"Installation","text":"<p>Currently available only from GitHub:</p> <pre><code>pip install git+https://github.com/r-hyperspec/pyperspec.git\n</code></pre>"},{"location":"#quick-demo","title":"Quick Demo","text":"<pre><code>import pyspc\nimport numpy as np\nimport pandas as pd\n\nspc = np.random.rand(10, 20) # Here is you spectra in unfolded structure\nwl = np.linspace(1000,2000,20) # Array of wavelength/wavenumbers\nmeta_data = pd.DataFrame({\"group\": ..., \"date\": ...,}) # Additional meta-data\n\n# Create the object\nsf = pyspc.SpectraFrame(spc, wl=wl, data=data)\n\n# Easy meta-data manipulation\nsf.A\nsf[\"A\"]\nsf[\"E\"] = ...\n\n# Easy data slicing/filtering, similar to hyperSpec\nsf[:,:,500:1000] # Cut wavelenght range to [500, 1000]\nsf[:5,:,:5, True] # Use iloc style to get only first five spectra and first five wavenumbers\nsf.query(\"group == 'Control'\") # Get only 'Control' group\n\n# Simple aggregation even with custom methods\nsf[:,:,500:1000].mean(groupby=[\"group\", \"date\"])\nsf.query(\"group = 'Control'\").apply(lamda x: np.sum(x**2), axis=0)\n\n# Chaining methods\nsf_processed = (\n    sf.query(\"group = 'Control'\")\n    .mean(groupby=\"date\")\n    .smooth(\"savgol\", window_length=7, polyorder=2)\n    .sbaseline(\"rubberband\")\n    .normalize(\"area\")\n)\n\n# Select 3 random spectra and plot them colored by \"date\"\nsf.sample(3).plot(colors=\"date\")\n\n# Export to wide pandas DataFrame\nsf.to_pandas()\n</code></pre>"},{"location":"#acknowlegments","title":"Acknowlegments","text":"<ul> <li>This project was a continuation of ibcp/pyspectra. We acknowlege support and contribution of Emanuel Institute of Biochemical Physics, RAS</li> <li>This project has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie Actions (Grant Agreement 861122) as part of IMAGE-IN project.</li> <li>The project was developed as part of secondment at Chemometrix GmbH</li> <li>Supervision was from Chemometrix GmbH, Leibniz-IPHT, and BMD Software</li> </ul>"},{"location":"api-spectraframe/","title":"SpectraFrame","text":""},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame","title":"<code>pyspc.spectra.SpectraFrame</code>","text":"<p>A class to represent unfolded spectral data</p> Source code in <code>pyspc\\spectra.py</code> <pre><code>class SpectraFrame:\n    \"\"\"A class to represent unfolded spectral data\"\"\"\n\n    # ----------------------------------------------------------------------\n    # Constructor\n\n    def __init__(  # noqa: C901\n        self,\n        spc: ArrayLike,\n        wl: Optional[ArrayLike] = None,\n        data: Optional[pd.DataFrame] = None,\n    ) -&gt; None:\n        \"\"\"Create a new SpectraFrame object\n\n        Parameters\n        ----------\n        spc : ArrayLike\n            Spectral data. A 2D array where each row represents a spectrum.\n        wl : Optional[ArrayLike], optional\n            Spectral coordinates, i.e. wavelengths, wavenumbers, etc.\n            If None, then the range 0..N is used, by default None.\n        data : Optional[pd.DataFrame], optional\n            Additional meta-data, by default None\n\n        Raises\n        ------\n        ValueError\n            If the provided data or wl is not valid (i.e. wrong shape, etc.)\n        ValueError\n            If shapes do not match (e.g. number of rows in spc and data)\n\n        Examples\n        --------\n        &gt;&gt;&gt; np.random.seed(42)\n        &gt;&gt;&gt; sf = SpectraFrame(\n        ...     np.random.rand(4,5),\n        ...     wl=np.linspace(600,660,5),\n        ...     data={\"group\": list(\"AABB\")}\n        ... )\n        &gt;&gt;&gt; print(sf)\n              600.0  ...     660.0 group\n        0  0.374540  ...  0.156019     A\n        1  0.155995  ...  0.708073     A\n        2  0.020584  ...  0.181825     B\n        3  0.183405  ...  0.291229     B\n        \"\"\"\n        # Prepare SPC\n        spc = np.array(spc)\n        if spc.ndim == 1:\n            spc = spc.reshape(1, -1)\n        elif spc.ndim &gt; 2:\n            raise ValueError(\"Invalid spc is provided!\")\n\n        # Prepare wl\n        if wl is None:\n            wl = np.arange(spc.shape[1])\n        else:\n            wl = np.array(wl)\n            if wl.ndim &gt; 1:\n                raise ValueError(\"Invalid wl is provided\")\n\n        # Parse data\n        if data is None:\n            data = pd.DataFrame(index=range(len(spc)), columns=None)\n        if not isinstance(data, pd.DataFrame):\n            data = pd.DataFrame(data)\n\n        # Checks\n        if spc.shape[1] != len(wl):\n            raise ValueError(\n                \"length of wavelength must be equal to number of columns in spc\"\n            )\n\n        if spc.shape[0] != data.shape[0]:\n            raise ValueError(\n                \"data must have the same number of instances(rows) as spc has\"\n            )\n\n        self.spc = spc\n        self.wl = wl\n        self.data = data\n\n    # ----------------------------------------------------------------------\n    # Internal helpers\n\n    def _parse_string_or_column_param(\n        self, param: Union[str, pd.Series, np.ndarray, list, tuple]\n    ) -&gt; pd.Series:\n        \"\"\"Manage different types of method arguments\n\n        Many methods provide flexibility in the input parameters. For example,\n        a user can provide either a string with the name of a data column or\n        an array-like structure with the same number of elements as the number\n        of spectra. This method helps to parse and convert the input to a\n        standard format.\n\n        Parameters\n        ----------\n        param : Union[str, pd.Series, np.ndarray, list, tuple]\n            The input parameter to be parsed\n\n        Returns\n        -------\n        pd.Series\n            A pandas Series with the same index as the data\n\n        Raises\n        ------\n        TypeError\n            If it was not possible to parse the input parameter\n\n        Examples\n        --------\n        &gt;&gt;&gt; sf = SpectraFrame(np.random.rand(2,5), data={\"group\": list(\"AB\")})\n        &gt;&gt;&gt; sf._parse_string_or_column_param(\"group\")\n        0    A\n        1    B\n        Name: group, dtype: object\n        &gt;&gt;&gt; sf._parse_string_or_column_param([\"C\", \"D\"])\n        0    C\n        1    D\n        dtype: object\n        &gt;&gt;&gt; sf._parse_string_or_column_param(pd.Series([\"C\", \"D\"],index=[3,4]))\n        0    C\n        1    D\n        dtype: object\n        \"\"\"\n        if isinstance(param, str) and (param in self.data.columns):\n            return self.data[param]\n        elif isinstance(param, pd.Series) and (param.shape[0] == self.nspc):\n            return pd.Series(param.values, index=self.index)\n        elif (\n            isinstance(param, np.ndarray)\n            and (param.ndim == 1)\n            and (param.shape[0] == self.nspc)\n        ):\n            return pd.Series(param, index=self.index)\n        elif isinstance(param, (list, tuple)) and (len(param) == self.nspc):\n            return pd.Series(param, index=self.index)\n        else:\n            raise TypeError(\n                \"Invalid parameter. It must be either a string of a data \"\n                \"column name or pd.Series / np.array / list / tuple of \"\n                \"lenght equal to number of spectra. \"\n            )\n\n    # ----------------------------------------------------------------------\n    # Properties for a quick access\n\n    @property\n    def shape(self) -&gt; Tuple[int, int, int]:\n        \"\"\"A tuple representing the dimensionality of the Spectra\n\n        Returns\n        -------\n        Tuple[int, int, int]:\n            A tuple of the following structure:\n            1. number of spectra (i.e. number of rows)\n            2. number of data columns\n            3. number of wavelength points\n        \"\"\"\n        return self.nspc, self.data.shape[1], self.nwl\n\n    @property\n    def nwl(self) -&gt; int:\n        \"\"\"Number of wavelength points\"\"\"\n        return len(self.wl)\n\n    @property\n    def nspc(self) -&gt; int:\n        \"\"\"Number of spectra in the object\"\"\"\n        return self.spc.shape[0]\n\n    @property\n    def is_equally_spaced(self) -&gt; bool:\n        \"\"\"Are wavelength values equally spaced?\"\"\"\n        return len(np.unique(self.wl[1:] - self.wl[:-1])) == 1\n\n    # ----------------------------------------------------------------------\n    # Coping\n\n    def copy(self) -&gt; \"SpectraFrame\":\n        return SpectraFrame(\n            spc=self.spc.copy(), wl=self.wl.copy(), data=self.data.copy()\n        )\n\n    # ----------------------------------------------------------------------\n    # Accessing data\n    def _parse_getitem_tuple(self, slicer: tuple) -&gt; tuple:\n        \"\"\"Parse the tuple provided in __getitem__/__setitem__ methods\n\n        Basically, validates the tuple and formats each part of the tuple\n        to be in a standard format: slice or np.array with iloc values.\n\n        Parameters\n        ----------\n        slicer : tuple\n            The tuple provided in __getitem__ method\n\n        Returns\n        -------\n        tuple\n            A tuple of three slices: row, column, and wavelength\n\n        Raises\n        ------\n        ValueError\n            If the provided slicer is not valid\n        \"\"\"\n        if not ((type(slicer) == tuple) and (len(slicer) in [3, 4])):\n            raise ValueError(\n                \"Invalid subset value. Provide 3 values in format &lt;row, column, wl&gt;\"\n                \"or 4 values in format &lt;row, column, wl, True/False&gt;\"\n            )\n\n        use_iloc = False\n        if len(slicer) == 4:\n            use_iloc = bool(slicer[3])\n            slicer = slicer[:3]\n\n        rows, cols, wls = slicer\n\n        # From labels to indices\n        row_selector = _parse_getitem_single_selector(\n            self.data.index, rows, iloc=use_iloc\n        )\n        col_selector = _parse_getitem_single_selector(\n            self.data.columns, cols, iloc=use_iloc\n        )\n        wl_selector = _parse_getitem_single_selector(\n            pd.Index(self.wl), wls, iloc=use_iloc\n        )\n\n        return row_selector, col_selector, wl_selector\n\n    def __getitem__(self, given: Union[str, tuple]) -&gt; Union[pd.Series, \"SpectraFrame\"]:\n        \"\"\"Get a subset of the SpectraFrame\n\n        Provides a logic for the `[...]` operator.\n        Two types of slicing are supported:\n        1. Single string - returns a corresponding column from the data\n        2. Tuple of three or four slicers - returns a subset of the SpectraFrame\n        The latter is working similar to `hyperSpec` package in R. Basically,\n        it allows to slice the data by as\n        `sf[rows, cols, wls]` or `sf[rows, cols, wls, is_iloc]` where `rows`, `cols`,\n        and `wls` can be either a single value, a list of values, a slice, or a boolean\n        vector; and `is_iloc` is a boolean flag to indicate whether the slicing is\n        done by iloc or by label (similar to `wl_index` in `hyperSpec`).\n\n        Warning\n        -------\n        The slicing is behaving like in `pandas` DataFrame, so the last value\n        in the slice is included in the output.\n\n        Parameters\n        ----------\n        given : Union[str, tuple]\n            Single string or a tuple of three slicers and an optional flag\n\n        Returns\n        -------\n        Union[pd.Series, SpectraFrame]\n            Eirther a single column from the data or a subset of the SpectraFrame\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Generate a SpectraFrame\n        &gt;&gt;&gt; spc = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n        &gt;&gt;&gt; wl = np.array([400, 500, 600])\n        &gt;&gt;&gt; data = pd.DataFrame(\n        ...     {\"A\": [10, 11, 12], \"B\": [13, 14, 15], \"C\": [16, 17, 18]},\n        ...     index=[5, 6, 7],\n        ... )\n        &gt;&gt;&gt; sf = SpectraFrame(spc, wl, data)\n        &gt;&gt;&gt; print(sf)\n           400  500  600   A   B   C\n        5  1.0  2.0  3.0  10  13  16\n        6  4.0  5.0  6.0  11  14  17\n        7  7.0  8.0  9.0  12  15  18\n\n        &gt;&gt;&gt; # Get a single column\n        &gt;&gt;&gt; print(sf[\"A\"])\n        5    10\n        6    11\n        7    12\n        Name: A, dtype: int64\n\n        &gt;&gt;&gt; # Get a subset of the SpectraFrame\n        &gt;&gt;&gt; print(sf[:5, :, :500])\n           400  500   A   B   C\n        5  1.0  2.0  10  13  16\n\n        &gt;&gt;&gt; # Access by iloc indexes\n        &gt;&gt;&gt; print(sf[:1, :, :1, True])\n           400   A   B   C\n        5  1.0  10  13  16\n\n        &gt;&gt;&gt; print(sf[6:, 'B':'C', 500:])\n           500  600   B   C\n        6  5.0  6.0  14  17\n        7  8.0  9.0  15  18\n\n        &gt;&gt;&gt; print(sf[6:, 'B':'C', [400, 600]])\n           400  600   B   C\n        6  4.0  6.0  14  17\n        7  7.0  9.0  15  18\n\n        &gt;&gt;&gt; print(sf[:, :, 400])\n           400   A   B   C\n        5  1.0  10  13  16\n        6  4.0  11  14  17\n        7  7.0  12  15  18\n\n        &gt;&gt;&gt; print(sf[:, :, 550])\n        Traceback (most recent call last):\n        ValueError: Unexpected selector [550]\n\n        &gt;&gt;&gt; print(sf[:, :, 510:550])\n            A   B   C\n        5  10  13  16\n        6  11  14  17\n        7  12  15  18\n\n        &gt;&gt;&gt; print(sf[:, :, 350:450])\n           400   A   B   C\n        5  1.0  10  13  16\n        6  4.0  11  14  17\n        7  7.0  12  15  18\n        \"\"\"\n        if isinstance(given, str):\n            return self.data[given]\n\n        row_slice, col_slice, wl_slice = self._parse_getitem_tuple(given)\n        return SpectraFrame(\n            spc=self.spc[row_slice, wl_slice],\n            wl=self.wl[wl_slice],\n            data=self.data.iloc[row_slice, col_slice],\n        )\n\n    def __setitem__(self, given: Union[str, tuple], value: Any) -&gt; None:\n        \"\"\"Set values in a subset of the SpectraFrame\n\n        Provides a logic for the `frame[&lt;given&gt;] = &lt;value&gt;` operator.\n        &lt;given&gt; has the same format as in `__getitem__` method. The &lt;value&gt;\n        can be either a single value or array-like structure with the same\n        number of elements as the subset of the SpectraFrame.\n\n        Warning\n        -------\n        Either one of wavelenght or data columns (i.e. second or third slicers)\n        must be `:`. Otherwise, it is not clear where to put the value.\n        Therefore the method will raise an error in such cases,\n        e.g. `sf[:, \"a\", 400:1000] = 10`.\n\n\n        Parameters\n        ----------\n        given : Union[str, tuple]\n            Single string or a tuple of three slicers\n        value : Any\n            The value to be set in the subset\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Generate a SpectraFrame\n        &gt;&gt;&gt; spc = np.arange(9).reshape(3, 3)\n        &gt;&gt;&gt; sf = SpectraFrame(spc, [400, 500, 600], {\"A\": [10, 11, 12]})\n        &gt;&gt;&gt; print(sf)\n           400  500  600   A\n        0    0    1    2  10\n        1    3    4    5  11\n        2    6    7    8  12\n\n        &gt;&gt;&gt; # Add a column\n        &gt;&gt;&gt; sf[\"B\"] = [20, 21, 22]\n        &gt;&gt;&gt; print(sf)\n           400  500  600   A   B\n        0    0    1    2  10  20\n        1    3    4    5  11  21\n        2    6    7    8  12  22\n\n        &gt;&gt;&gt; # Set a single value\n        &gt;&gt;&gt; sf[0, :, 500] = 100\n        &gt;&gt;&gt; print(sf)\n           400  500  600   A   B\n        0    0  100    2  10  20\n        1    3    4    5  11  21\n        2    6    7    8  12  22\n\n        &gt;&gt;&gt; # Set a subset\n        &gt;&gt;&gt; sf[1:, :, 500:] = [[200, 201], [300, 301]]\n        &gt;&gt;&gt; print(sf)\n           400  500  600   A   B\n        0    0  100    2  10  20\n        1    3  200  201  11  21\n        2    6  300  301  12  22\n\n        &gt;&gt;&gt; # Set a subset with iloc\n        &gt;&gt;&gt; sf[:2, :, :2, True] = 0\n        &gt;&gt;&gt; print(sf)\n           400  500  600   A   B\n        0    0    0    2  10  20\n        1    0    0  201  11  21\n        2    6  300  301  12  22\n\n        &gt;&gt;&gt; # Invalid selector\n        &gt;&gt;&gt; sf[:, [\"A\", \"B\"], :500] = 0\n        Traceback (most recent call last):\n        ValueError: Invalid slicing...\n        \"\"\"\n        if isinstance(given, str):\n            return self.data.__setitem__(given, value)\n\n        row_slice, col_slice, wl_slice = self._parse_getitem_tuple(given)\n        if _is_empty_slice(col_slice) and not _is_empty_slice(wl_slice):\n            self.spc[row_slice, wl_slice] = value\n        elif not _is_empty_slice(col_slice) and _is_empty_slice(wl_slice):\n            self.data.iloc[row_slice, col_slice] = value\n        else:\n            raise ValueError(\n                \"Invalid slicing. Either data columns or \"\n                \"wavelengths indexes must be `:`\"\n            )\n\n    def __getattr__(self, name) -&gt; pd.Series:\n        return getattr(self.data, name)\n\n    def query(self, expr: str) -&gt; \"SpectraFrame\":\n        \"\"\"Filter spectra using pandas DataFrame.query\n\n        Parameters\n        -----------\n        expr : str\n            Query expression\n\n        Returns\n        -------\n        SpectraFrame\n            A new SpectraFrame with the filtered data\n\n        Examples\n        --------\n        &gt;&gt;&gt; np.random.seed(42)\n        &gt;&gt;&gt; sf = SpectraFrame(np.random.rand(4, 5), data={\"group\": list(\"AABB\")})\n        &gt;&gt;&gt; print(sf)\n                  0  ...         4 group\n        0  0.374540  ...  0.156019     A\n        1  0.155995  ...  0.708073     A\n        2  0.020584  ...  0.181825     B\n        3  0.183405  ...  0.291229     B\n        &gt;&gt;&gt; sf.query(\"group == 'A'\")\n                  0  ...         4 group\n        0  0.374540  ...  0.156019     A\n        1  0.155995  ...  0.708073     A\n        \"\"\"\n        indices = self.data.query(expr).index\n        return self[indices, :, :]\n\n    # ----------------------------------------------------------------------\n    # Arithmetic operations +, -, *, /, **, abs, round, ceil, etc.\n\n    def __add__(self, other: Any) -&gt; \"SpectraFrame\":\n        if isinstance(other, type(self)):\n            other = other.spc\n        return SpectraFrame(spc=self.spc.__add__(other), wl=self.wl, data=self.data)\n\n    def __sub__(self, other: Any) -&gt; \"SpectraFrame\":\n        if isinstance(other, type(self)):\n            other = other.spc\n        return SpectraFrame(spc=self.spc.__sub__(other), wl=self.wl, data=self.data)\n\n    def __mul__(self, other: Any) -&gt; \"SpectraFrame\":\n        if isinstance(other, type(self)):\n            other = other.spc\n        return SpectraFrame(spc=self.spc.__mul__(other), wl=self.wl, data=self.data)\n\n    def __truediv__(self, other: Any) -&gt; \"SpectraFrame\":\n        if isinstance(other, type(self)):\n            other = other.spc\n        return SpectraFrame(spc=self.spc.__truediv__(other), wl=self.wl, data=self.data)\n\n    def __pow__(self, other: Any) -&gt; \"SpectraFrame\":\n        return SpectraFrame(spc=self.spc.__pow__(other), wl=self.wl, data=self.data)\n\n    def __radd__(self, other: Any) -&gt; \"SpectraFrame\":\n        return SpectraFrame(spc=self.spc.__radd__(other), wl=self.wl, data=self.data)\n\n    def __rsub__(self, other: Any) -&gt; \"SpectraFrame\":\n        return SpectraFrame(spc=self.spc.__rsub__(other), wl=self.wl, data=self.data)\n\n    def __rmul__(self, other: Any) -&gt; \"SpectraFrame\":\n        return SpectraFrame(spc=self.spc.__rmul__(other), wl=self.wl, data=self.data)\n\n    def __rtruediv__(self, other: Any) -&gt; \"SpectraFrame\":\n        return SpectraFrame(\n            spc=self.spc.__rtruediv__(other), wl=self.wl, data=self.data\n        )\n\n    # def __iadd__(self, other: Any) -&gt; None:\n    #     if isinstance(other, type(self)):\n    #         other = other.spc\n    #     self.spc = self.spc.__add__(other)\n\n    # def __isub__(self, other: Any) -&gt; None:\n    #     if isinstance(other, type(self)):\n    #         other = other.spc\n    #     self.spc = self.spc.__sub__(other)\n\n    # def __imul__(self, other: Any) -&gt; None:\n    #     if isinstance(other, type(self)):\n    #         other = other.spc\n    #     self.spc = self.spc.__mul__(other)\n\n    # def __itruediv__(self, other: Any) -&gt; None:\n    #     if isinstance(other, type(self)):\n    #         other = other.spc\n    #     self.spc = self.spc.__truediv__(other)\n\n    def __abs__(self) -&gt; \"SpectraFrame\":\n        return SpectraFrame(spc=np.abs(self.spc), wl=self.wl, data=self.data)\n\n    def __round__(self, n: int) -&gt; \"SpectraFrame\":\n        return SpectraFrame(spc=np.round(self.spc, n), wl=self.wl, data=self.data)\n\n    def __floor__(self) -&gt; \"SpectraFrame\":\n        return SpectraFrame(spc=np.floor(self.spc), wl=self.wl, data=self.data)\n\n    def __ceil__(self) -&gt; \"SpectraFrame\":\n        return SpectraFrame(spc=np.ceil(self.spc), wl=self.wl, data=self.data)\n\n    def __trunc__(self) -&gt; \"SpectraFrame\":\n        return SpectraFrame(spc=np.trunc(self.spc), wl=self.wl, data=self.data)\n\n    # ----------------------------------------------------------------------\n    # Wavelengths\n\n    def resample_wl(\n        self, new_wl: np.ndarray, method=\"interp1d\", **kwargs\n    ) -&gt; \"SpectraFrame\":\n        \"\"\"Resample wavelengths, i.e. shift wavelenghts with interpolation\n\n        Parameters\n        ----------\n        new_wl : np.ndarray\n            New wavenumbers\n        method : str, optional\n            Method for interpolation. Currently only \"interp1d\" is supported.\n            Which is using `scipy.interpolate.interp1d` function.\n        kwargs : dict, optional\n            Additional parameters to be passed to the interpolator function.\n            See `scipy.interpolate.interp1d` docs for more details.\n\n        Returns\n        -------\n        SpectraFrame\n            A new SpectraFrame object with `new_wl` as wavenumbers, and\n            interpolated signal values as spectral data. `*.data` part\n            remains the same.\n\n        Raises\n        ------\n        NotImplementedError\n            Unimplemented method of interpolation.\n        \"\"\"\n        if method == \"interp1d\":\n            interpolator = scipy.interpolate.interp1d(x=self.wl, y=self.spc, **kwargs)\n            new_spc = interpolator(new_wl)\n        else:\n            raise NotImplementedError(\"Other methods not available yet\")\n\n        return SpectraFrame(new_spc, wl=new_wl, data=self.data)\n\n    # ----------------------------------------------------------------------\n    # Stats &amp; Applys\n    def _get_axis(self, axis, groupby=None) -&gt; int:\n        \"\"\"Get axis value in standard format\"\"\"\n        if groupby is not None:\n            return 0\n        if axis in [0, \"index\"]:\n            return 0\n        elif axis in [1, \"columns\"]:\n            return 1\n        else:\n            raise ValueError(f\"Unexpected `axis` value {axis}\")\n\n    def _get_groupby(self, groupby) -&gt; list[str]:\n        \"\"\"Format and validate groupby value\"\"\"\n        if groupby is None:\n            return None\n\n        # Grouped\n        if isinstance(groupby, str):\n            groupby = [groupby]\n\n        # Check the names are in the data\n        for name in groupby:\n            if name not in self.data.columns:\n                raise ValueError(f\"Column '{name}' is not presented in the data\")\n\n        return groupby\n\n    def _apply_func(\n        self,\n        func: Union[str, Callable],\n        *args,\n        data: np.ndarray = None,\n        axis: int = 1,\n        **kwargs,\n    ) -&gt; np.ndarray:\n        \"\"\"Apply a function alog an axis\n\n        Dispatches calculation to `np.apply_alog_axis` (if func is callable) or\n        `np.&lt;func&gt;` (if func is a string)\n\n        Parameters\n        ----------\n        func : Union[str, Callable]\n            Either a string with the name of numpy funciton, e.g \"max\", \"mean\", etc.\n            Or a callable function that can be passed to `numpy.apply_along_axis`\n        data : np.ndarray, optional\n            To which data apply the function, by default `self.spc`\n            This parameter is useful for cases when the function must be applied on\n            different parts of the spctral data, e.g. when groupby is used\n        axis : int, optional\n            Standard axis. Same as in `numpy` or `pandas`, by default 1\n\n        Returns\n        -------\n        np.ndarray\n            The output array. The shape of out is identical to the shape of data, except\n            along the axis dimension. This axis is removed, and replaced with new\n            dimensions equal to the shape of the return value of func. So if func\n            returns a scalar, the output will be eirther single row (axis=0) or\n            single column (axis=1) matrix.\n\n        Raises\n        ------\n        ValueError\n            Function with provided name `func` was not found in `numpy`\n        \"\"\"\n        # Check and prepare parameters\n        if data is None:\n            data = self.spc\n\n        if isinstance(func, str):\n            name = func\n            if hasattr(np, name):\n                func = getattr(np, name)\n            else:\n                raise ValueError(f\"Could not find function {name} in `numpy`\")\n\n            res: np.ndarray = func(data, *args, axis=axis, **kwargs)\n            # Functions like np.quantile behave differently than apply_alog_axis\n            # Here we make the shape of the matrix to be the same\n            if (res.ndim &gt; 1) and (axis == 1):\n                res = res.T\n        else:\n            res = np.apply_along_axis(func, axis, data, *args, **kwargs)\n\n        # Reshape the result to keep dimenstions\n        if res.ndim == 1:\n            res = res.reshape((1, -1)) if axis == 0 else res.reshape((-1, 1))\n\n        return res\n\n    def apply(\n        self,\n        func: Union[str, callable],\n        *args,\n        groupby: Union[str, list[str], None] = None,\n        axis: int = 0,\n        **kwargs,\n    ) -&gt; \"SpectraFrame\":\n        \"\"\"Apply function to the spectral data\n\n        Parameters\n        ----------\n        func : Union[str, callable]\n            Either a string with the name of numpy funciton, e.g \"max\", \"mean\", etc.\n            Or a callable function that can be passed to `numpy.apply_along_axis`\n        groupby : Union[str, list[str]], optional\n            Single or list of `data` column names to use for grouping the data.\n            By default None, so the function applied to the all spectral data.\n        axis : int, optional\n             Standard axis. Same as in `numpy` or `pandas`, by default 1 when groupby\n             is not provided, and 0 when provided.\n\n        Returns\n        -------\n        SpectraFrame\n            Output spectral frame where\n            * `out.spc` is the results of `func`\n            * `out.wl` either the same (axis=0 OR axis=1 and `nwl` matches)\n              or range 0..N (axis=1 and `nwl` does not match)\n            * `out.data` The same if axis=1. If axis=0, either empty (no grouping)\n                or represents the grouping.\n        \"\"\"\n\n        # Prepare arguments\n        axis = self._get_axis(axis, groupby)\n        groupby = self._get_groupby(groupby)\n\n        # Prepare default values\n        new_wl = self.wl if axis == 0 else None\n        new_data = self.data if axis == 1 else None\n\n        if groupby is None:\n            new_spc = self._apply_func(func, *args, axis=axis, **kwargs)\n        else:\n            # Prepare a dataframe for groupby aggregation\n            grouped = self.to_pandas().groupby(groupby, observed=True)[self.wl]\n\n            # Prepare list of group names as dicts {'column name': 'column value', ...}\n            keys = [i for i, _ in grouped]\n            groups = [dict(zip(groupby, gr)) for gr in keys]\n\n            # Apply to each group\n            spc_list = [\n                self._apply_func(func, *args, data=group.values, axis=0, **kwargs)\n                for _, group in grouped\n            ]\n            data_list = [\n                pd.DataFrame({**gr, \"group_index\": range(spc_list[i].shape[0])})\n                for i, gr in enumerate(groups)\n            ]\n\n            # Combine\n            new_spc = np.concatenate(spc_list, axis=0)\n            new_data = pd.concat(data_list, axis=0, ignore_index=True)\n\n        # If the applied function returns same number of wavelenghts\n        # we assume that wavelengths are the same, e.g. baseline,\n        # smoothing, etc.\n        if (new_wl is None) and (new_spc.shape[1] == self.nwl):\n            new_wl = self.wl\n\n        return SpectraFrame(new_spc, wl=new_wl, data=new_data)\n\n    def area(self) -&gt; \"SpectraFrame\":\n        \"\"\"Calculate area under the spectra\"\"\"\n        return SpectraFrame(\n            scipy.integrate.trapezoid(self.spc, x=self.wl, axis=1).reshape((-1, 1)),\n            wl=None,\n            data=self.data,\n        )\n\n    # ----------------------------------------------------------------------\n    # Dispatching to numpy methods\n    # TODO: It would be good to group the method declarations below\n\n    def min(\n        self, *args, groupby=None, axis=1, ignore_na=False, **kwargs\n    ) -&gt; \"SpectraFrame\":\n        func = \"min\" if not ignore_na else \"nanmin\"\n        return self.apply(func, *args, groupby=groupby, axis=axis, **kwargs)\n\n    def max(\n        self, *args, groupby=None, axis=1, ignore_na=False, **kwargs\n    ) -&gt; \"SpectraFrame\":\n        func = \"max\" if not ignore_na else \"nanmax\"\n        return self.apply(func, *args, groupby=groupby, axis=axis, **kwargs)\n\n    def sum(\n        self, *args, groupby=None, axis=1, ignore_na=False, **kwargs\n    ) -&gt; \"SpectraFrame\":\n        func = \"sum\" if not ignore_na else \"nansum\"\n        return self.apply(func, *args, groupby=groupby, axis=axis, **kwargs)\n\n    def mean(\n        self, *args, groupby=None, axis=1, ignore_na=False, **kwargs\n    ) -&gt; \"SpectraFrame\":\n        func = \"mean\" if not ignore_na else \"nanmean\"\n        return self.apply(func, *args, groupby=groupby, axis=axis, **kwargs)\n\n    def std(\n        self, *args, groupby=None, axis=1, ignore_na=False, **kwargs\n    ) -&gt; \"SpectraFrame\":\n        func = \"std\" if not ignore_na else \"nanstd\"\n        return self.apply(func, *args, groupby=groupby, axis=axis, **kwargs)\n\n    def median(\n        self, *args, groupby=None, axis=1, ignore_na=False, **kwargs\n    ) -&gt; \"SpectraFrame\":\n        func = \"median\" if not ignore_na else \"nanmedian\"\n        return self.apply(func, *args, groupby=groupby, axis=axis, **kwargs)\n\n    def mad(\n        self, *args, groupby=None, axis=1, ignore_na=False, **kwargs\n    ) -&gt; \"SpectraFrame\":\n        if ignore_na:\n            median = lambda x: np.nanmedian(x, *args, **kwargs)\n        else:\n            median = lambda x: np.median(x, *args, **kwargs)\n        return self.apply(\n            lambda x: median(np.absolute(x - median(x))), groupby=groupby, axis=axis\n        )\n\n    def quantile(\n        self, q, *args, groupby=None, axis=1, ignore_na=False, **kwargs\n    ) -&gt; \"SpectraFrame\":\n        func = \"quantile\" if not ignore_na else \"nanquantile\"\n        return self.apply(func, q, *args, groupby=groupby, axis=axis, **kwargs)\n\n    # ----------------------------------------------------------------------\n    # Manipulations\n    def normalize(\n        self,\n        method: str,\n        ignore_na: bool = True,\n        peak_range: Optional[Tuple[int]] = None,\n        **kwargs,\n    ) -&gt; \"SpectraFrame\":\n        \"\"\"Dispatcher for spectra normalization\n\n        Parameters\n        ----------\n        method : str\n            Method of normaliztion. Available options: '01', 'area', 'vector', 'mean',\n            'peak' (normalize by peak value in the given range). By default, peak value\n            is approximated by the maximum value in the given range. To use a different\n            method, use the `**kwargs` to pass to `around_max_peak_fit` function.\n        ignore_na : bool, optional\n            Ignore NaN values in the data, by default True\n        peak_range : tuple[int], optional\n            Range of wavelength/wavenumber to use for peak normalization.\n            If None (default), the whole range is used.\n\n        Returns\n        -------\n        SpectraFrame\n            A new SpectraFrame with normalized values\n\n        Raises\n        ------\n        NotImplementedError\n            Unknown or not implemented methods, e.g. peak normalization\n        \"\"\"\n        spc = self.copy()\n        if method == \"01\":\n            spc = spc - spc.min(axis=1, ignore_na=ignore_na)\n            spc = spc / spc.max(axis=1, ignore_na=ignore_na)\n        elif method == \"area\":\n            spc = spc / spc.area()\n        elif method == \"peak\":\n            if peak_range is None:\n                peak_range = (self.wl[0], self.wl[-1])\n\n            peak_intensities = around_max_peak_fit(\n                x=self[:, :, peak_range[0] : peak_range[1]].wl,\n                y=self[:, :, peak_range[0] : peak_range[1]].spc,\n                **kwargs,\n            )\n            spc = spc / peak_intensities.y_max.values.reshape((spc.nspc, -1))\n        elif method == \"vector\":\n            if ignore_na:\n                spc = spc / np.sqrt(\n                    np.nansum(np.power(spc.spc, 2), axis=1, keepdims=True)\n                )\n            else:\n                spc = spc / np.sqrt(np.sum(np.power(spc.spc, 2), axis=1, keepdims=True))\n        elif method == \"mean\":\n            spc = spc / spc.mean(axis=1, ignore_na=ignore_na)\n        else:\n            raise ValueError(\"Unknown normalization method\")\n\n        return spc\n\n    def smooth(self, method: str = \"savgol\", **kwargs) -&gt; \"SpectraFrame\":\n        \"\"\"Dispatcher for spectra smoothing\n\n        Parameters\n        ----------\n        method : str, optional\n            Method of smoothing. Currently, only \"savgol\" is avalialbe\n        kwargs : dict\n            Additional parameters to pass to the smoothing method\n\n        Returns\n        -------\n        SpectraFrame\n            A new frame with smoothed values\n\n        Raises\n        ------\n        NotImplementedError\n            Unknown or unimplemented smoothing method\n        \"\"\"\n        spc = self.copy()\n        if method == \"savgol\":\n            spc.spc = scipy.signal.savgol_filter(spc.spc, **kwargs)\n        else:\n            raise NotImplementedError(\"Method is not implemented yet\")\n\n        return spc\n\n    def baseline(self, method: str, **kwargs) -&gt; \"SpectraFrame\":\n        \"\"\"Dispatcher for spectra baseline estimation\n\n        Dispatches baseline correction to the corresponding method\n        in `pybaselines` package.\n        In addition, \"rubberband\" method is available.\n\n        Parameters\n        ----------\n        method : str\n            A name of the method in `pybaselines` package (e.g. \"airpls\", \"snip\"),\n            or \"rubberband\"\n        kwargs: dict\n            Additional parameters to pass to the baseline correction method\n\n        Returns\n        -------\n        SpectraFrame\n            A frame of estimated baselines\n\n        Raises\n        ------\n        ValueError\n            Unknown baseline method provided\n        \"\"\"\n        baseline_fitter = pybaselines.Baseline(x_data=self.wl)\n        if hasattr(baseline_fitter, method):\n            baseline_method = getattr(baseline_fitter, method)\n            baseline_func = lambda y: baseline_method(y, **kwargs)[0]\n        elif method == \"rubberband\":\n            baseline_func = lambda y: rubberband(self.wl, y, **kwargs)\n        else:\n            raise ValueError(\n                \"Unknown method. Method must be either \"\n                \"from `pybaselines` or 'rubberband'\"\n            )\n        return self.apply(baseline_func, axis=1)\n\n    def sbaseline(self, method: str, **kwargs) -&gt; \"SpectraFrame\":\n        \"\"\"Subtract baseline from the spectra\n\n        Same as `.baseline()`, but returns a new frame with subtracted baseline.\n        A shortcut for `SpectraFrame - SpectraFrame.baseline(...)`, allowing\n        to chain methods, e.g. `sf.smooth().sbaseline(\"snip\").normalize()`.\n        \"\"\"\n        return self - self.baseline(method, **kwargs).spc\n\n    # ----------------------------------------------------------------------\n    # Format conversion\n\n    def to_pandas(self, multiindex=False, string_names=False) -&gt; pd.DataFrame:\n        \"\"\"Convert to a pandas DataFrame\n\n        Parameters\n        ----------\n        multiindex : bool, optional\n            Adds an index level to columns separating spectral data (`spc`) from\n            meta data (`data`), by default False\n\n        Returns\n        -------\n        pd.DataFrame\n            Dataframe where spectral data is combined with meta data.\n            Wavelengths are used as column names for spectral data part.\n        \"\"\"\n        df = pd.concat(\n            [pd.DataFrame(self.spc, columns=self.wl, index=self.data.index), self.data],\n            axis=1,\n        )\n\n        if string_names:\n            df.columns = df.columns.map(str)\n\n        if multiindex:\n            df.columns = pd.MultiIndex.from_tuples(\n                [(\"spc\", wl) for wl in df.columns[: self.nwl]]\n                + [(\"data\", col) for col in df.columns[self.nwl :]]\n            )\n\n        return df\n\n    # ----------------------------------------------------------------------\n    # Misc.\n    def sample(self, n: int, replace: bool = False) -&gt; \"SpectraFrame\":\n        indx = np.random.choice(self.nspc, size=n, replace=replace)\n        return self[np.sort(indx), :, :, True]\n\n    def __sizeof__(self):\n        \"\"\"Estimate the total memory usage\"\"\"\n        return self.spc.__sizeof__() + self.data.__sizeof__() + self.wl.__sizeof__()\n\n    # ----------------------------------------------------------------------\n    # Plotting\n    def _parse_string_or_vector_param(self, param: Union[str, ArrayLike]) -&gt; pd.Series:\n        if isinstance(param, str) and (param == \"index\"):\n            return pd.Series(self.data.index)\n\n        if isinstance(param, str) and (param in self.data.columns):\n            return self.data[param]\n\n        if len(param) == self.nspc:\n            return pd.Series(param, index=self.data.index)\n\n        raise TypeError(\n            \"Invalid parameter. It must be either 'index' or data column name, or \"\n            \"array-like (i.e. np.array, list) of lenght equal to number of spectra.\"\n        )\n\n    def _prepare_plot_param(self, param: Union[None, str, ArrayLike]) -&gt; pd.Series:\n        if param is None:\n            param = pd.Series(\n                [\"dummy\"] * self.nspc, index=self.data.index, dtype=\"category\"\n            )\n        else:\n            param = self._parse_string_or_vector_param(param)\n\n        param = (\n            param.astype(\"category\")\n            .cat.add_categories(\"NA\")\n            .fillna(\"NA\")\n            .cat.remove_unused_categories()\n        )\n\n        return param\n\n    def plot(\n        self,\n        rows=None,\n        columns=None,\n        colors=None,\n        palette: Optional[list[str]] = None,\n        fig=None,\n        **kwargs: Any,\n    ):\n        # Split **kwargs\n        # TODO: Either add different kw params like https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html\n        # or infer from the name of kwarg where to put it.\n        show_legend = kwargs.get(\"legend\", colors is not None)\n        sharex = kwargs.get(\"sharex\", True)\n        sharey = kwargs.get(\"sharey\", True)\n\n        # Convert to series all 'string or vector' params\n        rows_series = self._prepare_plot_param(rows)\n        cols_series = self._prepare_plot_param(columns)\n        colorby_series = self._prepare_plot_param(colors)\n\n        nrows = len(rows_series.cat.categories)\n        ncols = len(cols_series.cat.categories)\n        ncolors = len(colorby_series.cat.categories)\n\n        # Prepare colors\n        if palette is None:\n            palette = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n            if ncolors &gt; len(palette):\n                palette = \"viridis\"\n\n        if isinstance(palette, str):\n            palette = [\n                rgb2hex(plt.get_cmap(palette, ncolors)(i)) for i in range(ncolors)\n            ]\n\n        cmap = dict(zip(colorby_series.cat.categories, palette[:ncolors]))\n        cmap.update({\"NA\": \"gray\"})\n        colors_series = colorby_series.cat.rename_categories(cmap)\n\n        # Get the figure and the axes for plot\n        if fig is None:\n            fig, axs = plt.subplots(\n                nrows,\n                ncols,\n                squeeze=False,\n                sharex=sharex,\n                sharey=sharey,\n                layout=\"tight\",\n            )\n        else:\n            axs = np.array(fig.get_axes()).reshape((nrows, ncols))\n\n        # Prepare legend lines if needed\n        legend_lines = [\n            Line2D([0], [0], color=c, lw=4) for c in colors_series.cat.categories\n        ]\n\n        # For each combination of row and column categories\n        for i, vrow in enumerate(rows_series.cat.categories):\n            for j, vcol in enumerate(cols_series.cat.categories):\n                # Filter all spectra related to the current subplot\n                rowfilter = np.array(rows_series == vrow) &amp; np.array(\n                    cols_series == vcol\n                )\n                if np.any(rowfilter):\n                    subdf = pd.DataFrame(self.spc[rowfilter, :], columns=self.wl)\n                    subdf.T.plot(\n                        kind=\"line\",\n                        ax=axs[i, j],\n                        color=colors_series[rowfilter],\n                        **kwargs,\n                    )\n\n                # Add legend if needed\n                if show_legend:\n                    axs[i, j].legend(legend_lines, colorby_series.cat.categories)\n                else:\n                    axs[i, j].legend().set_visible(False)\n\n                # For the first rows and columns set titles\n                if (i == 0) and (columns is not None):\n                    axs[i, j].set_title(str(vcol))\n                if (j == 0) and (rows is not None):\n                    axs[i, j].set_ylabel(str(vrow))\n\n        return fig, axs\n\n    # ----------------------------------------------------------------------\n    def _to_print_dataframe(self) -&gt; pd.DataFrame:\n        if self.nwl &gt; 3:\n            print_df = self[:, :, [0, -1], True].to_pandas()\n            print_df.insert(loc=1, column=\"...\", value=\"...\")\n        else:\n            print_df = self.to_pandas()\n        return print_df\n\n    def __str__(self) -&gt; str:\n        return self._to_print_dataframe().__str__()\n\n    def __repr__(self) -&gt; str:\n        return self._to_print_dataframe().__repr__()\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame-attributes","title":"Attributes","text":""},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.shape","title":"<code>shape: Tuple[int, int, int]</code>  <code>property</code>","text":"<p>A tuple representing the dimensionality of the Spectra</p> <p>Returns:</p> Type Description <code>Tuple[int, int, int]:</code> <p>A tuple of the following structure: 1. number of spectra (i.e. number of rows) 2. number of data columns 3. number of wavelength points</p>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.nwl","title":"<code>nwl: int</code>  <code>property</code>","text":"<p>Number of wavelength points</p>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.nspc","title":"<code>nspc: int</code>  <code>property</code>","text":"<p>Number of spectra in the object</p>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.is_equally_spaced","title":"<code>is_equally_spaced: bool</code>  <code>property</code>","text":"<p>Are wavelength values equally spaced?</p>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame-functions","title":"Functions","text":""},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.__init__","title":"<code>__init__(spc, wl=None, data=None)</code>","text":"<p>Create a new SpectraFrame object</p> <p>Parameters:</p> Name Type Description Default <code>spc</code> <code>ArrayLike</code> <p>Spectral data. A 2D array where each row represents a spectrum.</p> required <code>wl</code> <code>Optional[ArrayLike]</code> <p>Spectral coordinates, i.e. wavelengths, wavenumbers, etc. If None, then the range 0..N is used, by default None.</p> <code>None</code> <code>data</code> <code>Optional[DataFrame]</code> <p>Additional meta-data, by default None</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided data or wl is not valid (i.e. wrong shape, etc.)</p> <code>ValueError</code> <p>If shapes do not match (e.g. number of rows in spc and data)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; np.random.seed(42)\n&gt;&gt;&gt; sf = SpectraFrame(\n...     np.random.rand(4,5),\n...     wl=np.linspace(600,660,5),\n...     data={\"group\": list(\"AABB\")}\n... )\n&gt;&gt;&gt; print(sf)\n      600.0  ...     660.0 group\n0  0.374540  ...  0.156019     A\n1  0.155995  ...  0.708073     A\n2  0.020584  ...  0.181825     B\n3  0.183405  ...  0.291229     B\n</code></pre> Source code in <code>pyspc\\spectra.py</code> <pre><code>def __init__(  # noqa: C901\n    self,\n    spc: ArrayLike,\n    wl: Optional[ArrayLike] = None,\n    data: Optional[pd.DataFrame] = None,\n) -&gt; None:\n    \"\"\"Create a new SpectraFrame object\n\n    Parameters\n    ----------\n    spc : ArrayLike\n        Spectral data. A 2D array where each row represents a spectrum.\n    wl : Optional[ArrayLike], optional\n        Spectral coordinates, i.e. wavelengths, wavenumbers, etc.\n        If None, then the range 0..N is used, by default None.\n    data : Optional[pd.DataFrame], optional\n        Additional meta-data, by default None\n\n    Raises\n    ------\n    ValueError\n        If the provided data or wl is not valid (i.e. wrong shape, etc.)\n    ValueError\n        If shapes do not match (e.g. number of rows in spc and data)\n\n    Examples\n    --------\n    &gt;&gt;&gt; np.random.seed(42)\n    &gt;&gt;&gt; sf = SpectraFrame(\n    ...     np.random.rand(4,5),\n    ...     wl=np.linspace(600,660,5),\n    ...     data={\"group\": list(\"AABB\")}\n    ... )\n    &gt;&gt;&gt; print(sf)\n          600.0  ...     660.0 group\n    0  0.374540  ...  0.156019     A\n    1  0.155995  ...  0.708073     A\n    2  0.020584  ...  0.181825     B\n    3  0.183405  ...  0.291229     B\n    \"\"\"\n    # Prepare SPC\n    spc = np.array(spc)\n    if spc.ndim == 1:\n        spc = spc.reshape(1, -1)\n    elif spc.ndim &gt; 2:\n        raise ValueError(\"Invalid spc is provided!\")\n\n    # Prepare wl\n    if wl is None:\n        wl = np.arange(spc.shape[1])\n    else:\n        wl = np.array(wl)\n        if wl.ndim &gt; 1:\n            raise ValueError(\"Invalid wl is provided\")\n\n    # Parse data\n    if data is None:\n        data = pd.DataFrame(index=range(len(spc)), columns=None)\n    if not isinstance(data, pd.DataFrame):\n        data = pd.DataFrame(data)\n\n    # Checks\n    if spc.shape[1] != len(wl):\n        raise ValueError(\n            \"length of wavelength must be equal to number of columns in spc\"\n        )\n\n    if spc.shape[0] != data.shape[0]:\n        raise ValueError(\n            \"data must have the same number of instances(rows) as spc has\"\n        )\n\n    self.spc = spc\n    self.wl = wl\n    self.data = data\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.__getitem__","title":"<code>__getitem__(given)</code>","text":"<p>Get a subset of the SpectraFrame</p> <p>Provides a logic for the <code>[...]</code> operator. Two types of slicing are supported: 1. Single string - returns a corresponding column from the data 2. Tuple of three or four slicers - returns a subset of the SpectraFrame The latter is working similar to <code>hyperSpec</code> package in R. Basically, it allows to slice the data by as <code>sf[rows, cols, wls]</code> or <code>sf[rows, cols, wls, is_iloc]</code> where <code>rows</code>, <code>cols</code>, and <code>wls</code> can be either a single value, a list of values, a slice, or a boolean vector; and <code>is_iloc</code> is a boolean flag to indicate whether the slicing is done by iloc or by label (similar to <code>wl_index</code> in <code>hyperSpec</code>).</p> Warning <p>The slicing is behaving like in <code>pandas</code> DataFrame, so the last value in the slice is included in the output.</p> <p>Parameters:</p> Name Type Description Default <code>given</code> <code>Union[str, tuple]</code> <p>Single string or a tuple of three slicers and an optional flag</p> required <p>Returns:</p> Type Description <code>Union[Series, SpectraFrame]</code> <p>Eirther a single column from the data or a subset of the SpectraFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Generate a SpectraFrame\n&gt;&gt;&gt; spc = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n&gt;&gt;&gt; wl = np.array([400, 500, 600])\n&gt;&gt;&gt; data = pd.DataFrame(\n...     {\"A\": [10, 11, 12], \"B\": [13, 14, 15], \"C\": [16, 17, 18]},\n...     index=[5, 6, 7],\n... )\n&gt;&gt;&gt; sf = SpectraFrame(spc, wl, data)\n&gt;&gt;&gt; print(sf)\n   400  500  600   A   B   C\n5  1.0  2.0  3.0  10  13  16\n6  4.0  5.0  6.0  11  14  17\n7  7.0  8.0  9.0  12  15  18\n</code></pre> <pre><code>&gt;&gt;&gt; # Get a single column\n&gt;&gt;&gt; print(sf[\"A\"])\n5    10\n6    11\n7    12\nName: A, dtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; # Get a subset of the SpectraFrame\n&gt;&gt;&gt; print(sf[:5, :, :500])\n   400  500   A   B   C\n5  1.0  2.0  10  13  16\n</code></pre> <pre><code>&gt;&gt;&gt; # Access by iloc indexes\n&gt;&gt;&gt; print(sf[:1, :, :1, True])\n   400   A   B   C\n5  1.0  10  13  16\n</code></pre> <pre><code>&gt;&gt;&gt; print(sf[6:, 'B':'C', 500:])\n   500  600   B   C\n6  5.0  6.0  14  17\n7  8.0  9.0  15  18\n</code></pre> <pre><code>&gt;&gt;&gt; print(sf[6:, 'B':'C', [400, 600]])\n   400  600   B   C\n6  4.0  6.0  14  17\n7  7.0  9.0  15  18\n</code></pre> <pre><code>&gt;&gt;&gt; print(sf[:, :, 400])\n   400   A   B   C\n5  1.0  10  13  16\n6  4.0  11  14  17\n7  7.0  12  15  18\n</code></pre> <pre><code>&gt;&gt;&gt; print(sf[:, :, 550])\nTraceback (most recent call last):\nValueError: Unexpected selector [550]\n</code></pre> <pre><code>&gt;&gt;&gt; print(sf[:, :, 510:550])\n    A   B   C\n5  10  13  16\n6  11  14  17\n7  12  15  18\n</code></pre> <pre><code>&gt;&gt;&gt; print(sf[:, :, 350:450])\n   400   A   B   C\n5  1.0  10  13  16\n6  4.0  11  14  17\n7  7.0  12  15  18\n</code></pre> Source code in <code>pyspc\\spectra.py</code> <pre><code>def __getitem__(self, given: Union[str, tuple]) -&gt; Union[pd.Series, \"SpectraFrame\"]:\n    \"\"\"Get a subset of the SpectraFrame\n\n    Provides a logic for the `[...]` operator.\n    Two types of slicing are supported:\n    1. Single string - returns a corresponding column from the data\n    2. Tuple of three or four slicers - returns a subset of the SpectraFrame\n    The latter is working similar to `hyperSpec` package in R. Basically,\n    it allows to slice the data by as\n    `sf[rows, cols, wls]` or `sf[rows, cols, wls, is_iloc]` where `rows`, `cols`,\n    and `wls` can be either a single value, a list of values, a slice, or a boolean\n    vector; and `is_iloc` is a boolean flag to indicate whether the slicing is\n    done by iloc or by label (similar to `wl_index` in `hyperSpec`).\n\n    Warning\n    -------\n    The slicing is behaving like in `pandas` DataFrame, so the last value\n    in the slice is included in the output.\n\n    Parameters\n    ----------\n    given : Union[str, tuple]\n        Single string or a tuple of three slicers and an optional flag\n\n    Returns\n    -------\n    Union[pd.Series, SpectraFrame]\n        Eirther a single column from the data or a subset of the SpectraFrame\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Generate a SpectraFrame\n    &gt;&gt;&gt; spc = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n    &gt;&gt;&gt; wl = np.array([400, 500, 600])\n    &gt;&gt;&gt; data = pd.DataFrame(\n    ...     {\"A\": [10, 11, 12], \"B\": [13, 14, 15], \"C\": [16, 17, 18]},\n    ...     index=[5, 6, 7],\n    ... )\n    &gt;&gt;&gt; sf = SpectraFrame(spc, wl, data)\n    &gt;&gt;&gt; print(sf)\n       400  500  600   A   B   C\n    5  1.0  2.0  3.0  10  13  16\n    6  4.0  5.0  6.0  11  14  17\n    7  7.0  8.0  9.0  12  15  18\n\n    &gt;&gt;&gt; # Get a single column\n    &gt;&gt;&gt; print(sf[\"A\"])\n    5    10\n    6    11\n    7    12\n    Name: A, dtype: int64\n\n    &gt;&gt;&gt; # Get a subset of the SpectraFrame\n    &gt;&gt;&gt; print(sf[:5, :, :500])\n       400  500   A   B   C\n    5  1.0  2.0  10  13  16\n\n    &gt;&gt;&gt; # Access by iloc indexes\n    &gt;&gt;&gt; print(sf[:1, :, :1, True])\n       400   A   B   C\n    5  1.0  10  13  16\n\n    &gt;&gt;&gt; print(sf[6:, 'B':'C', 500:])\n       500  600   B   C\n    6  5.0  6.0  14  17\n    7  8.0  9.0  15  18\n\n    &gt;&gt;&gt; print(sf[6:, 'B':'C', [400, 600]])\n       400  600   B   C\n    6  4.0  6.0  14  17\n    7  7.0  9.0  15  18\n\n    &gt;&gt;&gt; print(sf[:, :, 400])\n       400   A   B   C\n    5  1.0  10  13  16\n    6  4.0  11  14  17\n    7  7.0  12  15  18\n\n    &gt;&gt;&gt; print(sf[:, :, 550])\n    Traceback (most recent call last):\n    ValueError: Unexpected selector [550]\n\n    &gt;&gt;&gt; print(sf[:, :, 510:550])\n        A   B   C\n    5  10  13  16\n    6  11  14  17\n    7  12  15  18\n\n    &gt;&gt;&gt; print(sf[:, :, 350:450])\n       400   A   B   C\n    5  1.0  10  13  16\n    6  4.0  11  14  17\n    7  7.0  12  15  18\n    \"\"\"\n    if isinstance(given, str):\n        return self.data[given]\n\n    row_slice, col_slice, wl_slice = self._parse_getitem_tuple(given)\n    return SpectraFrame(\n        spc=self.spc[row_slice, wl_slice],\n        wl=self.wl[wl_slice],\n        data=self.data.iloc[row_slice, col_slice],\n    )\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.__setitem__","title":"<code>__setitem__(given, value)</code>","text":"<p>Set values in a subset of the SpectraFrame</p> <p>Provides a logic for the <code>frame[&lt;given&gt;] = &lt;value&gt;</code> operator.  has the same format as in <code>__getitem__</code> method. The  can be either a single value or array-like structure with the same number of elements as the subset of the SpectraFrame. Warning <p>Either one of wavelenght or data columns (i.e. second or third slicers) must be <code>:</code>. Otherwise, it is not clear where to put the value. Therefore the method will raise an error in such cases, e.g. <code>sf[:, \"a\", 400:1000] = 10</code>.</p> <p>Parameters:</p> Name Type Description Default <code>given</code> <code>Union[str, tuple]</code> <p>Single string or a tuple of three slicers</p> required <code>value</code> <code>Any</code> <p>The value to be set in the subset</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Generate a SpectraFrame\n&gt;&gt;&gt; spc = np.arange(9).reshape(3, 3)\n&gt;&gt;&gt; sf = SpectraFrame(spc, [400, 500, 600], {\"A\": [10, 11, 12]})\n&gt;&gt;&gt; print(sf)\n   400  500  600   A\n0    0    1    2  10\n1    3    4    5  11\n2    6    7    8  12\n</code></pre> <pre><code>&gt;&gt;&gt; # Add a column\n&gt;&gt;&gt; sf[\"B\"] = [20, 21, 22]\n&gt;&gt;&gt; print(sf)\n   400  500  600   A   B\n0    0    1    2  10  20\n1    3    4    5  11  21\n2    6    7    8  12  22\n</code></pre> <pre><code>&gt;&gt;&gt; # Set a single value\n&gt;&gt;&gt; sf[0, :, 500] = 100\n&gt;&gt;&gt; print(sf)\n   400  500  600   A   B\n0    0  100    2  10  20\n1    3    4    5  11  21\n2    6    7    8  12  22\n</code></pre> <pre><code>&gt;&gt;&gt; # Set a subset\n&gt;&gt;&gt; sf[1:, :, 500:] = [[200, 201], [300, 301]]\n&gt;&gt;&gt; print(sf)\n   400  500  600   A   B\n0    0  100    2  10  20\n1    3  200  201  11  21\n2    6  300  301  12  22\n</code></pre> <pre><code>&gt;&gt;&gt; # Set a subset with iloc\n&gt;&gt;&gt; sf[:2, :, :2, True] = 0\n&gt;&gt;&gt; print(sf)\n   400  500  600   A   B\n0    0    0    2  10  20\n1    0    0  201  11  21\n2    6  300  301  12  22\n</code></pre> <pre><code>&gt;&gt;&gt; # Invalid selector\n&gt;&gt;&gt; sf[:, [\"A\", \"B\"], :500] = 0\nTraceback (most recent call last):\nValueError: Invalid slicing...\n</code></pre> Source code in <code>pyspc\\spectra.py</code> <pre><code>def __setitem__(self, given: Union[str, tuple], value: Any) -&gt; None:\n    \"\"\"Set values in a subset of the SpectraFrame\n\n    Provides a logic for the `frame[&lt;given&gt;] = &lt;value&gt;` operator.\n    &lt;given&gt; has the same format as in `__getitem__` method. The &lt;value&gt;\n    can be either a single value or array-like structure with the same\n    number of elements as the subset of the SpectraFrame.\n\n    Warning\n    -------\n    Either one of wavelenght or data columns (i.e. second or third slicers)\n    must be `:`. Otherwise, it is not clear where to put the value.\n    Therefore the method will raise an error in such cases,\n    e.g. `sf[:, \"a\", 400:1000] = 10`.\n\n\n    Parameters\n    ----------\n    given : Union[str, tuple]\n        Single string or a tuple of three slicers\n    value : Any\n        The value to be set in the subset\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Generate a SpectraFrame\n    &gt;&gt;&gt; spc = np.arange(9).reshape(3, 3)\n    &gt;&gt;&gt; sf = SpectraFrame(spc, [400, 500, 600], {\"A\": [10, 11, 12]})\n    &gt;&gt;&gt; print(sf)\n       400  500  600   A\n    0    0    1    2  10\n    1    3    4    5  11\n    2    6    7    8  12\n\n    &gt;&gt;&gt; # Add a column\n    &gt;&gt;&gt; sf[\"B\"] = [20, 21, 22]\n    &gt;&gt;&gt; print(sf)\n       400  500  600   A   B\n    0    0    1    2  10  20\n    1    3    4    5  11  21\n    2    6    7    8  12  22\n\n    &gt;&gt;&gt; # Set a single value\n    &gt;&gt;&gt; sf[0, :, 500] = 100\n    &gt;&gt;&gt; print(sf)\n       400  500  600   A   B\n    0    0  100    2  10  20\n    1    3    4    5  11  21\n    2    6    7    8  12  22\n\n    &gt;&gt;&gt; # Set a subset\n    &gt;&gt;&gt; sf[1:, :, 500:] = [[200, 201], [300, 301]]\n    &gt;&gt;&gt; print(sf)\n       400  500  600   A   B\n    0    0  100    2  10  20\n    1    3  200  201  11  21\n    2    6  300  301  12  22\n\n    &gt;&gt;&gt; # Set a subset with iloc\n    &gt;&gt;&gt; sf[:2, :, :2, True] = 0\n    &gt;&gt;&gt; print(sf)\n       400  500  600   A   B\n    0    0    0    2  10  20\n    1    0    0  201  11  21\n    2    6  300  301  12  22\n\n    &gt;&gt;&gt; # Invalid selector\n    &gt;&gt;&gt; sf[:, [\"A\", \"B\"], :500] = 0\n    Traceback (most recent call last):\n    ValueError: Invalid slicing...\n    \"\"\"\n    if isinstance(given, str):\n        return self.data.__setitem__(given, value)\n\n    row_slice, col_slice, wl_slice = self._parse_getitem_tuple(given)\n    if _is_empty_slice(col_slice) and not _is_empty_slice(wl_slice):\n        self.spc[row_slice, wl_slice] = value\n    elif not _is_empty_slice(col_slice) and _is_empty_slice(wl_slice):\n        self.data.iloc[row_slice, col_slice] = value\n    else:\n        raise ValueError(\n            \"Invalid slicing. Either data columns or \"\n            \"wavelengths indexes must be `:`\"\n        )\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.query","title":"<code>query(expr)</code>","text":"<p>Filter spectra using pandas DataFrame.query</p> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>str</code> <p>Query expression</p> required <p>Returns:</p> Type Description <code>SpectraFrame</code> <p>A new SpectraFrame with the filtered data</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; np.random.seed(42)\n&gt;&gt;&gt; sf = SpectraFrame(np.random.rand(4, 5), data={\"group\": list(\"AABB\")})\n&gt;&gt;&gt; print(sf)\n          0  ...         4 group\n0  0.374540  ...  0.156019     A\n1  0.155995  ...  0.708073     A\n2  0.020584  ...  0.181825     B\n3  0.183405  ...  0.291229     B\n&gt;&gt;&gt; sf.query(\"group == 'A'\")\n          0  ...         4 group\n0  0.374540  ...  0.156019     A\n1  0.155995  ...  0.708073     A\n</code></pre> Source code in <code>pyspc\\spectra.py</code> <pre><code>def query(self, expr: str) -&gt; \"SpectraFrame\":\n    \"\"\"Filter spectra using pandas DataFrame.query\n\n    Parameters\n    -----------\n    expr : str\n        Query expression\n\n    Returns\n    -------\n    SpectraFrame\n        A new SpectraFrame with the filtered data\n\n    Examples\n    --------\n    &gt;&gt;&gt; np.random.seed(42)\n    &gt;&gt;&gt; sf = SpectraFrame(np.random.rand(4, 5), data={\"group\": list(\"AABB\")})\n    &gt;&gt;&gt; print(sf)\n              0  ...         4 group\n    0  0.374540  ...  0.156019     A\n    1  0.155995  ...  0.708073     A\n    2  0.020584  ...  0.181825     B\n    3  0.183405  ...  0.291229     B\n    &gt;&gt;&gt; sf.query(\"group == 'A'\")\n              0  ...         4 group\n    0  0.374540  ...  0.156019     A\n    1  0.155995  ...  0.708073     A\n    \"\"\"\n    indices = self.data.query(expr).index\n    return self[indices, :, :]\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.resample_wl","title":"<code>resample_wl(new_wl, method='interp1d', **kwargs)</code>","text":"<p>Resample wavelengths, i.e. shift wavelenghts with interpolation</p> <p>Parameters:</p> Name Type Description Default <code>new_wl</code> <code>ndarray</code> <p>New wavenumbers</p> required <code>method</code> <code>str</code> <p>Method for interpolation. Currently only \"interp1d\" is supported. Which is using <code>scipy.interpolate.interp1d</code> function.</p> <code>'interp1d'</code> <code>kwargs</code> <code>dict</code> <p>Additional parameters to be passed to the interpolator function. See <code>scipy.interpolate.interp1d</code> docs for more details.</p> <code>{}</code> <p>Returns:</p> Type Description <code>SpectraFrame</code> <p>A new SpectraFrame object with <code>new_wl</code> as wavenumbers, and interpolated signal values as spectral data. <code>*.data</code> part remains the same.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Unimplemented method of interpolation.</p> Source code in <code>pyspc\\spectra.py</code> <pre><code>def resample_wl(\n    self, new_wl: np.ndarray, method=\"interp1d\", **kwargs\n) -&gt; \"SpectraFrame\":\n    \"\"\"Resample wavelengths, i.e. shift wavelenghts with interpolation\n\n    Parameters\n    ----------\n    new_wl : np.ndarray\n        New wavenumbers\n    method : str, optional\n        Method for interpolation. Currently only \"interp1d\" is supported.\n        Which is using `scipy.interpolate.interp1d` function.\n    kwargs : dict, optional\n        Additional parameters to be passed to the interpolator function.\n        See `scipy.interpolate.interp1d` docs for more details.\n\n    Returns\n    -------\n    SpectraFrame\n        A new SpectraFrame object with `new_wl` as wavenumbers, and\n        interpolated signal values as spectral data. `*.data` part\n        remains the same.\n\n    Raises\n    ------\n    NotImplementedError\n        Unimplemented method of interpolation.\n    \"\"\"\n    if method == \"interp1d\":\n        interpolator = scipy.interpolate.interp1d(x=self.wl, y=self.spc, **kwargs)\n        new_spc = interpolator(new_wl)\n    else:\n        raise NotImplementedError(\"Other methods not available yet\")\n\n    return SpectraFrame(new_spc, wl=new_wl, data=self.data)\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.apply","title":"<code>apply(func, *args, groupby=None, axis=0, **kwargs)</code>","text":"<p>Apply function to the spectral data</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Union[str, callable]</code> <p>Either a string with the name of numpy funciton, e.g \"max\", \"mean\", etc. Or a callable function that can be passed to <code>numpy.apply_along_axis</code></p> required <code>groupby</code> <code>Union[str, list[str]]</code> <p>Single or list of <code>data</code> column names to use for grouping the data. By default None, so the function applied to the all spectral data.</p> <code>None</code> <code>axis</code> <code>int</code> <p>Standard axis. Same as in <code>numpy</code> or <code>pandas</code>, by default 1 when groupby  is not provided, and 0 when provided.</p> <code>0</code> <p>Returns:</p> Type Description <code>SpectraFrame</code> <p>Output spectral frame where * <code>out.spc</code> is the results of <code>func</code> * <code>out.wl</code> either the same (axis=0 OR axis=1 and <code>nwl</code> matches)   or range 0..N (axis=1 and <code>nwl</code> does not match) * <code>out.data</code> The same if axis=1. If axis=0, either empty (no grouping)     or represents the grouping.</p> Source code in <code>pyspc\\spectra.py</code> <pre><code>def apply(\n    self,\n    func: Union[str, callable],\n    *args,\n    groupby: Union[str, list[str], None] = None,\n    axis: int = 0,\n    **kwargs,\n) -&gt; \"SpectraFrame\":\n    \"\"\"Apply function to the spectral data\n\n    Parameters\n    ----------\n    func : Union[str, callable]\n        Either a string with the name of numpy funciton, e.g \"max\", \"mean\", etc.\n        Or a callable function that can be passed to `numpy.apply_along_axis`\n    groupby : Union[str, list[str]], optional\n        Single or list of `data` column names to use for grouping the data.\n        By default None, so the function applied to the all spectral data.\n    axis : int, optional\n         Standard axis. Same as in `numpy` or `pandas`, by default 1 when groupby\n         is not provided, and 0 when provided.\n\n    Returns\n    -------\n    SpectraFrame\n        Output spectral frame where\n        * `out.spc` is the results of `func`\n        * `out.wl` either the same (axis=0 OR axis=1 and `nwl` matches)\n          or range 0..N (axis=1 and `nwl` does not match)\n        * `out.data` The same if axis=1. If axis=0, either empty (no grouping)\n            or represents the grouping.\n    \"\"\"\n\n    # Prepare arguments\n    axis = self._get_axis(axis, groupby)\n    groupby = self._get_groupby(groupby)\n\n    # Prepare default values\n    new_wl = self.wl if axis == 0 else None\n    new_data = self.data if axis == 1 else None\n\n    if groupby is None:\n        new_spc = self._apply_func(func, *args, axis=axis, **kwargs)\n    else:\n        # Prepare a dataframe for groupby aggregation\n        grouped = self.to_pandas().groupby(groupby, observed=True)[self.wl]\n\n        # Prepare list of group names as dicts {'column name': 'column value', ...}\n        keys = [i for i, _ in grouped]\n        groups = [dict(zip(groupby, gr)) for gr in keys]\n\n        # Apply to each group\n        spc_list = [\n            self._apply_func(func, *args, data=group.values, axis=0, **kwargs)\n            for _, group in grouped\n        ]\n        data_list = [\n            pd.DataFrame({**gr, \"group_index\": range(spc_list[i].shape[0])})\n            for i, gr in enumerate(groups)\n        ]\n\n        # Combine\n        new_spc = np.concatenate(spc_list, axis=0)\n        new_data = pd.concat(data_list, axis=0, ignore_index=True)\n\n    # If the applied function returns same number of wavelenghts\n    # we assume that wavelengths are the same, e.g. baseline,\n    # smoothing, etc.\n    if (new_wl is None) and (new_spc.shape[1] == self.nwl):\n        new_wl = self.wl\n\n    return SpectraFrame(new_spc, wl=new_wl, data=new_data)\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.area","title":"<code>area()</code>","text":"<p>Calculate area under the spectra</p> Source code in <code>pyspc\\spectra.py</code> <pre><code>def area(self) -&gt; \"SpectraFrame\":\n    \"\"\"Calculate area under the spectra\"\"\"\n    return SpectraFrame(\n        scipy.integrate.trapezoid(self.spc, x=self.wl, axis=1).reshape((-1, 1)),\n        wl=None,\n        data=self.data,\n    )\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.normalize","title":"<code>normalize(method, ignore_na=True, peak_range=None, **kwargs)</code>","text":"<p>Dispatcher for spectra normalization</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Method of normaliztion. Available options: '01', 'area', 'vector', 'mean', 'peak' (normalize by peak value in the given range). By default, peak value is approximated by the maximum value in the given range. To use a different method, use the <code>**kwargs</code> to pass to <code>around_max_peak_fit</code> function.</p> required <code>ignore_na</code> <code>bool</code> <p>Ignore NaN values in the data, by default True</p> <code>True</code> <code>peak_range</code> <code>tuple[int]</code> <p>Range of wavelength/wavenumber to use for peak normalization. If None (default), the whole range is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpectraFrame</code> <p>A new SpectraFrame with normalized values</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Unknown or not implemented methods, e.g. peak normalization</p> Source code in <code>pyspc\\spectra.py</code> <pre><code>def normalize(\n    self,\n    method: str,\n    ignore_na: bool = True,\n    peak_range: Optional[Tuple[int]] = None,\n    **kwargs,\n) -&gt; \"SpectraFrame\":\n    \"\"\"Dispatcher for spectra normalization\n\n    Parameters\n    ----------\n    method : str\n        Method of normaliztion. Available options: '01', 'area', 'vector', 'mean',\n        'peak' (normalize by peak value in the given range). By default, peak value\n        is approximated by the maximum value in the given range. To use a different\n        method, use the `**kwargs` to pass to `around_max_peak_fit` function.\n    ignore_na : bool, optional\n        Ignore NaN values in the data, by default True\n    peak_range : tuple[int], optional\n        Range of wavelength/wavenumber to use for peak normalization.\n        If None (default), the whole range is used.\n\n    Returns\n    -------\n    SpectraFrame\n        A new SpectraFrame with normalized values\n\n    Raises\n    ------\n    NotImplementedError\n        Unknown or not implemented methods, e.g. peak normalization\n    \"\"\"\n    spc = self.copy()\n    if method == \"01\":\n        spc = spc - spc.min(axis=1, ignore_na=ignore_na)\n        spc = spc / spc.max(axis=1, ignore_na=ignore_na)\n    elif method == \"area\":\n        spc = spc / spc.area()\n    elif method == \"peak\":\n        if peak_range is None:\n            peak_range = (self.wl[0], self.wl[-1])\n\n        peak_intensities = around_max_peak_fit(\n            x=self[:, :, peak_range[0] : peak_range[1]].wl,\n            y=self[:, :, peak_range[0] : peak_range[1]].spc,\n            **kwargs,\n        )\n        spc = spc / peak_intensities.y_max.values.reshape((spc.nspc, -1))\n    elif method == \"vector\":\n        if ignore_na:\n            spc = spc / np.sqrt(\n                np.nansum(np.power(spc.spc, 2), axis=1, keepdims=True)\n            )\n        else:\n            spc = spc / np.sqrt(np.sum(np.power(spc.spc, 2), axis=1, keepdims=True))\n    elif method == \"mean\":\n        spc = spc / spc.mean(axis=1, ignore_na=ignore_na)\n    else:\n        raise ValueError(\"Unknown normalization method\")\n\n    return spc\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.smooth","title":"<code>smooth(method='savgol', **kwargs)</code>","text":"<p>Dispatcher for spectra smoothing</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Method of smoothing. Currently, only \"savgol\" is avalialbe</p> <code>'savgol'</code> <code>kwargs</code> <code>dict</code> <p>Additional parameters to pass to the smoothing method</p> <code>{}</code> <p>Returns:</p> Type Description <code>SpectraFrame</code> <p>A new frame with smoothed values</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Unknown or unimplemented smoothing method</p> Source code in <code>pyspc\\spectra.py</code> <pre><code>def smooth(self, method: str = \"savgol\", **kwargs) -&gt; \"SpectraFrame\":\n    \"\"\"Dispatcher for spectra smoothing\n\n    Parameters\n    ----------\n    method : str, optional\n        Method of smoothing. Currently, only \"savgol\" is avalialbe\n    kwargs : dict\n        Additional parameters to pass to the smoothing method\n\n    Returns\n    -------\n    SpectraFrame\n        A new frame with smoothed values\n\n    Raises\n    ------\n    NotImplementedError\n        Unknown or unimplemented smoothing method\n    \"\"\"\n    spc = self.copy()\n    if method == \"savgol\":\n        spc.spc = scipy.signal.savgol_filter(spc.spc, **kwargs)\n    else:\n        raise NotImplementedError(\"Method is not implemented yet\")\n\n    return spc\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.baseline","title":"<code>baseline(method, **kwargs)</code>","text":"<p>Dispatcher for spectra baseline estimation</p> <p>Dispatches baseline correction to the corresponding method in <code>pybaselines</code> package. In addition, \"rubberband\" method is available.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>A name of the method in <code>pybaselines</code> package (e.g. \"airpls\", \"snip\"), or \"rubberband\"</p> required <code>kwargs</code> <p>Additional parameters to pass to the baseline correction method</p> <code>{}</code> <p>Returns:</p> Type Description <code>SpectraFrame</code> <p>A frame of estimated baselines</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Unknown baseline method provided</p> Source code in <code>pyspc\\spectra.py</code> <pre><code>def baseline(self, method: str, **kwargs) -&gt; \"SpectraFrame\":\n    \"\"\"Dispatcher for spectra baseline estimation\n\n    Dispatches baseline correction to the corresponding method\n    in `pybaselines` package.\n    In addition, \"rubberband\" method is available.\n\n    Parameters\n    ----------\n    method : str\n        A name of the method in `pybaselines` package (e.g. \"airpls\", \"snip\"),\n        or \"rubberband\"\n    kwargs: dict\n        Additional parameters to pass to the baseline correction method\n\n    Returns\n    -------\n    SpectraFrame\n        A frame of estimated baselines\n\n    Raises\n    ------\n    ValueError\n        Unknown baseline method provided\n    \"\"\"\n    baseline_fitter = pybaselines.Baseline(x_data=self.wl)\n    if hasattr(baseline_fitter, method):\n        baseline_method = getattr(baseline_fitter, method)\n        baseline_func = lambda y: baseline_method(y, **kwargs)[0]\n    elif method == \"rubberband\":\n        baseline_func = lambda y: rubberband(self.wl, y, **kwargs)\n    else:\n        raise ValueError(\n            \"Unknown method. Method must be either \"\n            \"from `pybaselines` or 'rubberband'\"\n        )\n    return self.apply(baseline_func, axis=1)\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.sbaseline","title":"<code>sbaseline(method, **kwargs)</code>","text":"<p>Subtract baseline from the spectra</p> <p>Same as <code>.baseline()</code>, but returns a new frame with subtracted baseline. A shortcut for <code>SpectraFrame - SpectraFrame.baseline(...)</code>, allowing to chain methods, e.g. <code>sf.smooth().sbaseline(\"snip\").normalize()</code>.</p> Source code in <code>pyspc\\spectra.py</code> <pre><code>def sbaseline(self, method: str, **kwargs) -&gt; \"SpectraFrame\":\n    \"\"\"Subtract baseline from the spectra\n\n    Same as `.baseline()`, but returns a new frame with subtracted baseline.\n    A shortcut for `SpectraFrame - SpectraFrame.baseline(...)`, allowing\n    to chain methods, e.g. `sf.smooth().sbaseline(\"snip\").normalize()`.\n    \"\"\"\n    return self - self.baseline(method, **kwargs).spc\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.to_pandas","title":"<code>to_pandas(multiindex=False, string_names=False)</code>","text":"<p>Convert to a pandas DataFrame</p> <p>Parameters:</p> Name Type Description Default <code>multiindex</code> <code>bool</code> <p>Adds an index level to columns separating spectral data (<code>spc</code>) from meta data (<code>data</code>), by default False</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Dataframe where spectral data is combined with meta data. Wavelengths are used as column names for spectral data part.</p> Source code in <code>pyspc\\spectra.py</code> <pre><code>def to_pandas(self, multiindex=False, string_names=False) -&gt; pd.DataFrame:\n    \"\"\"Convert to a pandas DataFrame\n\n    Parameters\n    ----------\n    multiindex : bool, optional\n        Adds an index level to columns separating spectral data (`spc`) from\n        meta data (`data`), by default False\n\n    Returns\n    -------\n    pd.DataFrame\n        Dataframe where spectral data is combined with meta data.\n        Wavelengths are used as column names for spectral data part.\n    \"\"\"\n    df = pd.concat(\n        [pd.DataFrame(self.spc, columns=self.wl, index=self.data.index), self.data],\n        axis=1,\n    )\n\n    if string_names:\n        df.columns = df.columns.map(str)\n\n    if multiindex:\n        df.columns = pd.MultiIndex.from_tuples(\n            [(\"spc\", wl) for wl in df.columns[: self.nwl]]\n            + [(\"data\", col) for col in df.columns[self.nwl :]]\n        )\n\n    return df\n</code></pre>"},{"location":"api-spectraframe/#pyspc.spectra.SpectraFrame.__sizeof__","title":"<code>__sizeof__()</code>","text":"<p>Estimate the total memory usage</p> Source code in <code>pyspc\\spectra.py</code> <pre><code>def __sizeof__(self):\n    \"\"\"Estimate the total memory usage\"\"\"\n    return self.spc.__sizeof__() + self.data.__sizeof__() + self.wl.__sizeof__()\n</code></pre>"}]}